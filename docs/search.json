[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelado de Riesgo crediticio en Python",
    "section": "",
    "text": "Preface\nSi alguna vez solicitó una tarjeta de crédito o un préstamo, sabrá que las empresas financieras procesan su información antes de tomar una decisión. Esto se debe a que otorgarle un préstamo puede tener un impacto financiero grave a su negocio. ¿Pero cómo toman una decisión? En este curso, aprenderá a preparar los datos de una solicitud de crédito. Después de eso, aplicará el aprendizaje automático y las reglas comerciales para reducir el riesgo y garantizar la rentabilidad. Utilizará dos conjuntos de datos que emulan aplicaciones de crédito reales y al mismo tiempo se centrarán en el valor empresarial."
  },
  {
    "objectID": "intro.html#comprender-el-riesgo-créditicio",
    "href": "intro.html#comprender-el-riesgo-créditicio",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.1 Comprender el riesgo créditicio",
    "text": "1.1 Comprender el riesgo créditicio\n\n1.1.1 ¿Qué es el riesgo crediticio?\nEl riesgo crediticio es el riesgo de que alguien que ha pedido dinero prestado no lo pague todo. Piense en este riesgo como la diferencia entre prestar dinero a una persona y comprar un bono del gobierno. Con los bonos gubernamentales, es casi seguro que se reembolsarán, pero no cuando se presta dinero a la gente. Un préstamo está en mora cuando la agencia crediticia está razonablemente segura de que el préstamo no será reembolsado. Usaremos modelos de Machine Learning para determinar esto.\nConsideremos este ejemplo: hemos prestado 300 dólares a alguien que ha realizado dos pagos pero no el pago final.\n\n\n\nPago\nFecha de Pago\nEstado del Préstamo\n\n\n\n\n$100\n15 de Junio\nNon-Default\n\n\n$100\n15 de Julio\nNon-Default\n\n\n$0\n15 de Agosto\nDefault\n\n\n\nEs en este punto cuando consideramos que el préstamo está en mora. Predecir esto de antemano nos resulta útil para estimar la pérdida esperada."
  },
  {
    "objectID": "intro.html#pérdida-esperada",
    "href": "intro.html#pérdida-esperada",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.2 Pérdida Esperada",
    "text": "1.2 Pérdida Esperada\nLa pérdida esperada es la cantidad que la empresa pierde como resultado del incumplimiento de un préstamo. La pérdida esperada es un cálculo simple de los siguientes tres componentes.\n\nLa probabilidad de incumplimiento (PDI), que es la probabilidad de que alguien incumpla con un préstamo.\nExposición en caso de incumplimiento (EXI), que es el monto pendiente en el momento del incumplimiento.\nLa pérdida en caso de incumplimiento (PEI), que es la relación entre la exposición y cualquier recuperación de la pérdida.\n\nSegún nuestro ejemplo, los $100 que nos debían son nuestra exposicíon, y si vendemos esa deuda por $20, nuestra pérdida en caso de impago sería del 80% .\nLa fórmula para la pérdida esperada es el producto de los tres componentes previos, es decir,\n\\[\nexpected\\_loss = PDI\\times EXI\\times PEI\n\\]\nEste curso se centrará en la probabilidad de incumplimiento."
  },
  {
    "objectID": "intro.html#tipos-de-datos-utilizados",
    "href": "intro.html#tipos-de-datos-utilizados",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.3 Tipos de datos utilizados",
    "text": "1.3 Tipos de datos utilizados\nPara modelar la probabilidad de incumplimiento generalmente tenemos dos tipos principales de datos disponibles:\n\nLos datos de la solicitud, que son datos que están directamente vinculados a la solicitud del préstamo, como la calificación del préstamo.\nDatos de comportamiento (Behavior), describen al destinatario del préstamo, como la duracción de empleo\n\n\n\nSolicitud\nComportamiento (behavior)\n\n\n\n\nTasa de interés\nAntiguedad del empleo\n\n\nCalificación\nIncumplimiento Historico\n\n\nCantidad\nIngreso\n\n\n\n\n\n1.3.1 Columnas de datos\nLos datos que utilizaremos para nuestras predicciones de probabilidad de incumplimiento incluyen una combinación. Esto es importante porque los datos de la aplicación (solicitud) no son tan buenos como los datos de la aplicación y el comportamiento (behavior) juntos. Entonces, se incluyen dos columnas que emulan los datos que se pueden comprar en las agencias de crédito.\nLa adquisión de datos externos es una práctica común en la mayoría de las organizaciones. Estas son las columnas disponibles en el conjunto de datos.\n\n\n\nColumna\nColumna\n\n\n\n\nIngresos\nGrado del préstamo\n\n\nEdad\nMonto del préstamo\n\n\nPropiedad de vivienda\nTasa de interés\n\n\nAntiguedad Laboral\nEstado del préstamo\n\n\nIntención del préstamo\nIncumplimientos históricos\n\n\nPorcentaje de ingresos\nDuración del historial crediticio\n\n\n\nAlgunos ejemplos son: ingresos personales, porcentaje del monto del préstamo sobre los ingresos de la persona y duración del historial crediticio. Considere el porcentaje de ingresos. Esto podría afectar el estado del préstamo si el monto del préstamo es mayor que sus ingresos, porque es posible que no puedan hacer frente a los pagos."
  },
  {
    "objectID": "intro.html#explorando-con-tablas-cruzadas",
    "href": "intro.html#explorando-con-tablas-cruzadas",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.4 Explorando con tablas cruzadas",
    "text": "1.4 Explorando con tablas cruzadas\nNuestros datos tienen 32 mil filas, lo que puede resultar difícil de ver todas a la vez.\nPrimero cargamos los datos, de la siguiente manera en Python.\n\nimport pandas as pd\ncr_loan = pd.read_csv(\"cr_loan2.csv\")\ncr_loan.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n22\n59000\nRENT\n123.0\nPERSONAL\nD\n35000\n16.02\n1\n0.59\nY\n3\n\n\n1\n21\n9600\nOWN\n5.0\nEDUCATION\nB\n1000\n11.14\n0\n0.10\nN\n2\n\n\n2\n25\n9600\nMORTGAGE\n1.0\nMEDICAL\nC\n5500\n12.87\n1\n0.57\nN\n3\n\n\n3\n23\n65500\nRENT\n4.0\nMEDICAL\nC\n35000\n15.23\n1\n0.53\nN\n2\n\n\n4\n24\n54400\nRENT\n8.0\nMEDICAL\nC\n35000\n14.27\n1\n0.55\nY\n4\n\n\n\n\n\n\n\nImportante mencionar que el paquete pandas nos permite manipular datos, dado que nuestros datos son tipo .csv entonces utilizamos la función .read_csv() de pandas. y por último la función head() nos permite ver las primeras 5 filas de nuestros conjunto de datos.\nAhora bien, usaremos la función crosstab() de pandas. Podemos usar esta función para ayudar a obtener una vista de alto nivel de los datos similar a las tablas dinámicas en Excel.\n\npd.crosstab(cr_loan[\"person_home_ownership\"], cr_loan[\"loan_status\"], \nvalues = cr_loan[\"loan_int_rate\"], aggfunc = \"mean\").round(2)\n\n\n\n\n\n\n\nloan_status\n0\n1\n\n\nperson_home_ownership\n\n\n\n\n\n\nMORTGAGE\n10.06\n13.43\n\n\nOTHER\n11.41\n13.56\n\n\nOWN\n10.75\n12.24\n\n\nRENT\n10.75\n12.97\n\n\n\n\n\n\n\nAquí, vemos que los datos se agruparon por estado del préstamo y propiedad de la vivienda, y luego se calculó la tasa de interés promedio."
  },
  {
    "objectID": "intro.html#explorar-con-imágenes",
    "href": "intro.html#explorar-con-imágenes",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.5 Explorar con Imágenes",
    "text": "1.5 Explorar con Imágenes\nAdemás de utilizar tablas cruzadas, podemos explorar el conjunto de datos visualmente. Para ello usaremos el paquete matplotlib para crear un diagrama de dispersión de la tasa de interés del préstamo y los ingresos del destinatario.\n\nimport matplotlib.pyplot as plt\nplt.scatter(cr_loan[\"person_income\"], cr_loan[\"loan_int_rate\"], c = \"blue\", alpha = 0.5)\nplt.xlabel(\"Ingreso Personal\")\nplt.ylabel(\"Tasa de interés del préstamo\")\nplt.show()\n\n\n\n\nAl igual que la tabla cruzada, los gráficos nos ayudan a obtener una vista de alto nivel de nuestros datos."
  },
  {
    "objectID": "intro.html#resumen",
    "href": "intro.html#resumen",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.6 Resumen",
    "text": "1.6 Resumen\n\nHemos definido el riesgo crediticio , los componentes de la pérdida esperada y los métodos para explorar los datos del riesgo crediticio con la intención de estimar la probabilidad de incumplimiento.\nAhora practiquemos un poco con Python."
  },
  {
    "objectID": "intro.html#ejercicio-en-python",
    "href": "intro.html#ejercicio-en-python",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.7 Ejercicio en Python",
    "text": "1.7 Ejercicio en Python\nConozcamos la estructura de los datos imprimiendola con ayuda de Python.\n\nprint(cr_loan.dtypes)\n\nperson_age                      int64\nperson_income                   int64\nperson_home_ownership          object\nperson_emp_length             float64\nloan_intent                    object\nloan_grade                     object\nloan_amnt                       int64\nloan_int_rate                 float64\nloan_status                     int64\nloan_percent_income           float64\ncb_person_default_on_file      object\ncb_person_cred_hist_length      int64\ndtype: object\n\n\nMiremos las primeras cinco filas de los datos.\n\nprint(cr_loan.head())\n\n   person_age  person_income person_home_ownership  person_emp_length  \\\n0          22          59000                  RENT              123.0   \n1          21           9600                   OWN                5.0   \n2          25           9600              MORTGAGE                1.0   \n3          23          65500                  RENT                4.0   \n4          24          54400                  RENT                8.0   \n\n  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n0    PERSONAL          D      35000          16.02            1   \n1   EDUCATION          B       1000          11.14            0   \n2     MEDICAL          C       5500          12.87            1   \n3     MEDICAL          C      35000          15.23            1   \n4     MEDICAL          C      35000          14.27            1   \n\n   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n0                 0.59                         Y                           3  \n1                 0.10                         N                           2  \n2                 0.57                         N                           3  \n3                 0.53                         N                           2  \n4                 0.55                         Y                           4  \n\n\nVeamos la distribución de montos de préstamo con un histograma.\n\nn, bin, patches = plt.hist(x = cr_loan[\"loan_amnt\"], bins = \"auto\", color = \"blue\", alpha = 0.7, rwidth = 0.85)\nplt.xlabel(\"Monto del préstamo\")\nplt.show( )\n\n\n\n\nCreemos un diagrama de dispersión de los ingresos y la edad de una persona. En este caso, el ingreso es la variable independiente y la edad es la variable dependiente.\n\nplt.scatter(cr_loan['person_income'], cr_loan['person_age'],c='blue', alpha=0.5)\nplt.xlabel('Personal Income')\nplt.ylabel('Persone Age')\nplt.show()\n\n\n\n\nCreemos una tabla cruzada de la intención del préstamo y el estado del préstamo.\n\nprint(pd.crosstab(cr_loan[\"loan_intent\"], cr_loan[\"loan_status\"], margins = True))\n\nloan_status            0     1    All\nloan_intent                          \nDEBTCONSOLIDATION   3722  1490   5212\nEDUCATION           5342  1111   6453\nHOMEIMPROVEMENT     2664   941   3605\nMEDICAL             4450  1621   6071\nPERSONAL            4423  1098   5521\nVENTURE             4872   847   5719\nAll                25473  7108  32581\n\n\nAhora creemos una tabla cruzada de propiedad de vivienda agrupada por loan_status y loan_grade:\n\nprint(pd.crosstab(cr_loan[\"person_home_ownership\"],[cr_loan[\"loan_status\"],cr_loan[\"loan_grade\"]]))\n\nloan_status               0                                 1             \\\nloan_grade                A     B     C    D    E   F  G    A     B    C   \nperson_home_ownership                                                      \nMORTGAGE               5219  3729  1934  658  178  36  0  239   324  321   \nOTHER                    23    29    11    9    2   0  0    3     5    6   \nOWN                     860   770   464  264   26   7  0   66    34   31   \nRENT                   3602  4222  2710  554  137  28  1  765  1338  981   \n\nloan_status                               \nloan_grade                D    E   F   G  \nperson_home_ownership                     \nMORTGAGE                553  161  61  31  \nOTHER                    11    6   2   0  \nOWN                      18   31   8   5  \nRENT                   1559  423  99  27  \n\n\nTabla cruzada de home_ownership, con loan_status y promedio de loan_percent_income\n\nprint(pd.crosstab(cr_loan[\"person_home_ownership\"], cr_loan[\"loan_status\"],\n              values=cr_loan[\"loan_percent_income\"], aggfunc=\"mean\"))\n\nloan_status                   0         1\nperson_home_ownership                    \nMORTGAGE               0.146504  0.184882\nOTHER                  0.143784  0.300000\nOWN                    0.180013  0.297358\nRENT                   0.144611  0.264859\n\n\nPor último cree un diagrama de caja del porcentaje del préstamo de los ingresos de la persona agrupada por loan_status\n\ncr_loan.boxplot(column = ['loan_percent_income'], by = 'loan_status')\nplt.title('Average Percent Income by Loan Status')\nplt.suptitle('')\nplt.show()"
  },
  {
    "objectID": "intro.html#valores-atípicos-en-los-datos-crediticios",
    "href": "intro.html#valores-atípicos-en-los-datos-crediticios",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.8 Valores atípicos en los datos crediticios",
    "text": "1.8 Valores atípicos en los datos crediticios\nComo ocurre con cualquier probelma de Machine Learning, la preparación de datos es el primer paso. ¿Pero por qué? cuando nuestros datos están preparados adecuadamente, reducimos el tiempo de entrenamiento de nuestros modelos de aprendizaje automático. Además, los datos preparados también pueden tener un impacto positivo en el rendimiento de nuestro modelo. Esto es importante porque queremos que nuestros modelos predigan los incumplimientos correctamente con la mayor frecuencia posible. Considere este gráfico de la República de China.\n\nEste muestra la precisión de tres modelos diferentes sobre los mismos datos en diferentes etapas de procesamiento. La línea azul claro representa un modelo entrenado con datos ordenados y preparados, mientras que el modelo de la línea naranja se entrenó con datos sin procesar. La línea azul claro representa el modelo más preciso, porque la curva está más cerca de la esquina superior izquierda. Veremos más gráficos como este más adelante cuando verifiquemos la precisión de nuestros modelos.\n\n1.8.1 Valores atípicos y rendimiento\nEl primer tipo de preparación que veremos es la detección y eliminación de valores atípicos. Desafortunadamente, los sistemas de entrada de datos que producen datos incorrectos son bastante comunes. Si el especialista en ingreso de datos estaba cansado o distraído, puede ingresar valores incorrectos en nuestro sistema. También es posible que las herramientas de ingestas de datos creen valores erróneos en nuestros datos como resultado de problemas técnicos o fallas del sistema.\n\n\n\n\n\n\n\n\nEntradas (Feature)\nCoeficiente con valores atípicos\nCoeficientes sin valores atípicos\n\n\n\n\nTasa de interés\n0.2\n0.01\n\n\nAntiguedad Laboral\n0.5\n0.6\n\n\nIngresos\n0.6\n0.75\n\n\n\nCon valores atípicos en nuestros datos de entrenamiento, nuestros modelos predictivos tendrán dificultades para estimar parámetros como los coeficientes. Esto puede hacer que nuestros modelos no predigan tantos incumplimientos. Piense en los coeficientes como cuánto se pondera cada columna o característica para determinar el estado del préstamo. Observe las diferencias de coeficientes en el ejemplo de la tabla. Es posible que los valores atíplicos en la tasa de interés pueden hacer que esa columna tenga mucho más peso de lo normal. Esto afectará las predicciones.\n\n\n1.8.2 Detectar valores atípicos con tablas cruzadas\nUna forma de detectar valores atípicos es utilizar tablas cruzadas con funciones agregadas como las que ya hemos mostrados en la sección anterior.\nAquí utilizaremos una tabla cruzada de los datos de nuestros préstamos de crédito como antes para encontrar la tasa de interés promedio.\n\npd.crosstab(cr_loan[\"person_home_ownership\"], cr_loan[\"loan_status\"],\nvalues = cr_loan[\"loan_int_rate\"], aggfunc = \"mean\").round(2)\n\n\n\n\n\n\n\nloan_status\n0\n1\n\n\nperson_home_ownership\n\n\n\n\n\n\nMORTGAGE\n10.06\n13.43\n\n\nOTHER\n11.41\n13.56\n\n\nOWN\n10.75\n12.24\n\n\nRENT\n10.75\n12.97\n\n\n\n\n\n\n\nPara este ejemplo, podríamos esperar ver valores a la izquierda con nuestros datos normales. Sin embargo, tal como se muestra en la figura de abajo, podría haber algunos valores extremos en los datos que darían como resultado los datos de la derecha de la imagen. Esto causaría problemas con el modelado. Imaginese tener una tasa de interés del 50%.\n\nOtra forma de detectar valores atípicos es utilizar imagenes. Para ello podemos utilizar fácilmente gráficos como histogramas y diagramas de dispersión, que vimos previamente. }\n\nplt.scatter(cr_loan['person_emp_length'], cr_loan['loan_int_rate'],c='blue', alpha=0.5)\nplt.xlabel('Duración de empleo de persona')\nplt.ylabel('Tasa de interés del préstamo')\nplt.show()\n\n\n\n\nAquí, podemos ver que un par de registros tienen la duración del empleo de una persona establecida en más de 100 años. Esto sugeriría que dos solicitantes de préstamo tienen más de 136 años. Esto, al menos por ahora, no es posible.\n\n\n1.8.3 Eliminar valores atípicos\nSabemos que los valores atípicos son un problema y queremos eliminarlos, pero ¿cómo? Podemos usar fácilmente el método drop() del paquete pandas para eliminar filas de nuestros datos.\nPrimero usamos un subconjunto básico de Python para encontrar filas con una duración de empleo de nuestra persona mayor a 60.\n\nindices = cr_loan[cr_loan[\"person_emp_length\"] &gt;= 60].index\ncr_loan.drop(indices, inplace = True)\n\nLo que esto devuelve es la posición del índice de esa fila en nuestro marco de datos. A partir, de ahí, llamamos al método drop en nuestro marco de datos para que elimine las filas del marco de datos que coindicen con las posiciones de índice encontradas anteriormente.\n\nplt.scatter(cr_loan['person_emp_length'], cr_loan['loan_int_rate'],c='blue', alpha=0.5)\nplt.xlabel('Duración de empleo de persona')\nplt.ylabel('Tasa de interés del préstamo')\nplt.show()\n\n\n\n\nAhora podemos ver visualmente que los valores atípicos se han eliminado según nuestros criterios y los datos parecen mucho más realistas.\n\n\n1.8.4 Practica\nImprimamos la tabla cruzada de loan_status y person_home_ownership con el máximo de person_emp_length\n\nprint(pd.crosstab(cr_loan[\"loan_status\"],cr_loan[\"person_home_ownership\"],\n        values=cr_loan[\"person_emp_length\"], aggfunc=\"max\"))\n\nperson_home_ownership  MORTGAGE  OTHER   OWN  RENT\nloan_status                                       \n0                          38.0   24.0  31.0  41.0\n1                          34.0   11.0  17.0  27.0\n\n\nMuy bien. Ahora, creemos una matriz de índices para registros con una duración de empleo (person_emp_length) superior a 60 y guardelo como indices.\n\nindices = cr_loan[cr_loan[\"person_emp_length\"] &gt; 60].index\n\nEliminemos los registros de los datos usando la matriz de indices y cree un nuevo marco de datos llamado cr_loan_new.\n\ncr_loan_new = cr_loan.drop(indices)\n\nImpriamos la tabla cruzada de antes, pero en su lugar usemos ambos min y max.\n\nprint(pd.crosstab(cr_loan_new['loan_status'],cr_loan_new['person_home_ownership'],\n            values=cr_loan_new['person_emp_length'], aggfunc=['min','max']))\n\n                           min                      max                  \nperson_home_ownership MORTGAGE OTHER  OWN RENT MORTGAGE OTHER   OWN  RENT\nloan_status                                                              \n0                          0.0   0.0  0.0  0.0     38.0  24.0  31.0  41.0\n1                          0.0   0.0  0.0  0.0     34.0  11.0  17.0  27.0\n\n\nVisualicemos un diagrama de dispersión de la edad de la persona en el eje x y loan_amnt en el eje y.\n\nplt.scatter(cr_loan['person_age'], cr_loan['loan_amnt'], c='blue', alpha=0.5)\nplt.xlabel(\"Person Age\")\nplt.ylabel(\"Loan Amount\")\nplt.show()\n\n\n\n\nAhora utilicemos .drop() para eliminar los valores atípicos y crear cr_loan_new.\n\ncr_loan_new = cr_loan.drop(cr_loan[cr_loan['person_age'] &gt; 100].index)\n\nCree un diagrama de dispersión de la edad en el eje x y la tasa de interés del préstamo en el eje y con una etiqueta para loan_status.\n\nimport matplotlib\nimport matplotlib.pyplot as plt\ncolors = [\"blue\",\"red\"]\nplt.scatter(cr_loan_new['person_age'], cr_loan_new['loan_int_rate'],\n            c = cr_loan_new['loan_status'],\n            cmap = matplotlib.colors.ListedColormap(colors),\n            alpha=0.5)\nplt.xlabel(\"Person Age\")\nplt.ylabel(\"Loan Interest Rate\")\nplt.show()"
  },
  {
    "objectID": "intro.html#riesgos-con-datos-faltantes-en-los-datos-de-préstamo",
    "href": "intro.html#riesgos-con-datos-faltantes-en-los-datos-de-préstamo",
    "title": "1  Exploración y preparación de datos de préstamos",
    "section": "1.9 Riesgos con datos Faltantes en los datos de préstamo",
    "text": "1.9 Riesgos con datos Faltantes en los datos de préstamo\nUna vez eliminados los valores atípicos de nuestro conjunto de datos, ahora podemos centrarnos en otro problema con los datos crediticios y es cuando faltan datos.\n\n1.9.1 ¿Qué datos faltan?\nNormalmente, podría pensar que faltan datos cuando falta una fila completa, pero esa no es la única forma en que pueden faltar datos. Es posible que falten datos cuando hay valores nulos en lugar de valores reales. También puede ser una cadena vacía en lugar de una cadena real. En este curso, nos referimos a datos faltantes cuando no estén presentes valores específicos, no cuando falten filas enteras de datos.\nSi vemos una fila de datos con valores faltantes en un marco de datos de Pandas, se verá así.\n\nVemos NAN, en el campo de duración de empleo, en lugar de un valor.\n\n\n1.9.2 Similitudes con valores atípicos\nUn problema relacionado con los datos faltantes es similar a los probelmas causados por los valores atípicos en el sentido de que afecta negativamente el rendimiento del modelo predictivo. Puede sesgar nuestro modelo de maneras imprevistas, lo que puede afectar la forma en que predecimos los incumplimientos. Esto podría llevarnos a predecir una gran cantidad de incumplimientos que en realidad no son incumplimientos porque el modelo está sesgado hacia los incumplimientos. Además, muchos modelos de aprendizaje automático en Python no ignoran automáticamente los valores faltantes y, a menudo, arrojan errores y dejan de entrenar.\nA continuación se muestran algunos ejemplos de datos faltantes y posibles resultados. Si hay valores nulos en columnas numéricas o de cadena , el modelo arrojará un error.\n\n\n\nTipo dato missing\nPosible Resultado\n\n\n\n\nNULL en columna numerica\nError\n\n\nNULL en columna string\nError\n\n\n\n\n\n1.9.3 Cómo manejar los datos faltantes\nEntonces, ¿cómo manejamos los datos faltantes? En la mayoría de los casos se trata de tres maneras. A veces necesitamos reemplazar los valores faltantes. Esto podría reemplazar un valor nulo con el promedio de esa columna. Otras veces eliminamos la fila con datos faltantes todos juntos. Por ejemplo, si hay valores nulos en el monto del préstamo, debes eliminar esas filas por completo. A veces también nos faltan valores. Este, sin embargo, no es el caso con la mayoría de los datos de préstamos. Comprender los datos lo dirigirá hacia una de estas tres acciones.\n\nPor ejemplo, si el estado del préstamo es nulo, es posible que el préstamo se haya procesado recientemente en nuestro sistema.\nA veces hay un retraso en los datos y se necesita tiempo adicional para el procesamiento. En este caso, deberíamos eliminar toda la fila.\nOtro ejemplo es cuando falta la edad de la persona. Aquí, podríamos reemplazar los valores de edad que faltan con la mediana de la edad de todos.\n\n\n\n\n\n\n\n\n\nMissing Data\nInterpretación\nAcción\n\n\n\n\nNULL in loan_status\nPréstamo recientemente aprovado\nEliminar de los datos de predicción\n\n\nNULL in person_age\nEdad no registrada ni revelada\nReemplazar con mediana\n\n\n\n\n\n1.9.4 Encontrar datos faltantes\nPero, ¿cómo encontramos los datos faltantes? Con Pandas, podemos encontrar datos faltantes como nulos usando la función isnull() y la función de sum() para contar las filas a las que les faltan datos. Al combinar las funciones isnull, sum y any, contamos todos los valores nulos en cada columna.\n\nnull_columns = cr_loan.columns[cr_loan.isnull().any()]\ncr_loan[null_columns].isnull().sum()\n\nperson_emp_length     895\nloan_int_rate        3116\ndtype: int64\n\n\nComo puede notar, esto produce una tabla que muestra el recuento de registros con valores nulos en los datos.\n\n\n1.9.5 Reemplazo de datos faltantes\nSi decidimos reemplazar los datos faltantes, podemos llamar al método .fillna() de pandas junto con funciones agregadas. Esto reemplazará solo los valores faltantes.\nEn este ejemplo, que muestraré a continuación, reemplazamos las tasas de interés nulas con el promedio de todas las tasas de interés en los datos.\n\ncr_loan[\"loan_int_rate\"].fillna((cr_loan[\"loan_int_rate\"].mean()), inplace = True)\n\n\nPuede notar que el resultado es que ya no tenemos datos nulos en la variable loan_int_rate\n\nnull_columns = cr_loan.columns[cr_loan.isnull().any()]\ncr_loan[null_columns].isnull().sum()\n\nperson_emp_length    895\ndtype: int64\n\n\n\n\n1.9.6 Eliminar datos faltantes\nEliminar filas con datos faltantes es como eliminar filas con valores atípicos, como el el video anterior. Usamos el método de caída de pandas. Aquí, encontramos las filas con datos faltantes usando isnull y luego eliminamos las filas del conjunto de datos por completo.\n\nindices = cr_loan[\"person_emp_length\"].isnull().index\ncr_loan.drop(indices, inplace = True)\n\n\nnull_columns = cr_loan.columns[cr_loan.isnull().any()]\ncr_loan[null_columns].isnull().sum()\n\nSeries([], dtype: float64)\n\n\nEntonces, hemos aprendido qué son los datos faltantes, cómo manejarlos y algunos ejemplos de cómo los procesaremos."
  },
  {
    "objectID": "summary.html#regresión-logística-para-la-probabilidad-de-incumplimiento",
    "href": "summary.html#regresión-logística-para-la-probabilidad-de-incumplimiento",
    "title": "2  Regresión logistica para incumplimiento",
    "section": "2.1 Regresión logística para la probabilidad de incumplimiento",
    "text": "2.1 Regresión logística para la probabilidad de incumplimiento\nAhora que ya hemos eliminado tanto valores atípicos como los datos faltantes de nuestro conjunto de datos, podemos comenzar a modelar para predecir la probabilidad de incumplimiento.\n\n2.1.1 Probabilidad de incumplimiento\nRecuerde que la probabilidad de incumplimiento es la probabilidad de que alguien no pague un préstamo. Esto se expresa como una probabilidad que es un valor entre cero y uno. Estas probabilidades están asociadas con nuestra columna de estado del préstamo, donde un 1 es un incumplimiento y un 0 es un no incumplimiento.\n\n\n2.1.2 Predecir probabilidades\nPara obtener estas probabilidades, entrenamos modelos de aprendizaje automático en nuestras columnas de datos crediticios, conocidas como características, para que los modelos aprendan a usar los datos para predecir las probabilidades.\n\n\n\n\n\n\n\n\nProbabilidad de incumplimiento\nInterpretación\nPredicción loan_status\n\n\n\n\n0.4\nPoco probable que incumpla\n0\n\n\n0.90\nEs muy probable que incumpla\n1\n\n\n0.1\nEs muy poco probable que incumpla\n0\n\n\n\nEste tipo de modelos se conocen como modelos de clasificación, donde la clase es predeterminada o no predeterminada. En la industria se utilizan frencuentemente dos modelos. Se trata de regresiones logísticas y árboles de decisión. Ambos modelos pueden predecir la probabilidad de incumplimiento y decirnos qué tan improbable es cada columna para las predicciones.\n\n\n\n2.1.3 Regresión Logística\nLa regresión logística es como una regresión líneal pero solo produce un valor entre 0 y 1.\n\\[\n\\underbrace{Y = \\beta_0\n+ (\\beta_1*x_1) + (\\beta_2*X_2) + . . . }_{\\mbox{Regresión Lineal}} \\hspace{1cm} \\underbrace{P(loan_status = 1) = \\frac{1}{1 + e^{-Y}}}_{\\mbox{Regresión Logística}}\n\\]\nObserve que la ecuación de la regresión líneal es en realidad parte de la regresión logística. Las regresiones logísticas funcionan mejor con los datos cuando lo que determina un incumplimiento o no incumplimiento puede variar mucho.\n\nPiense aquí en la intersección con el eje \\(y\\), que son las probabilidades logarítmicas de no incumplimiento. Esta es otra forma de expresar la probabilidad general de no incumplimiento.\n\n\n2.1.4 Entrenar una regresión logística\nEn este curso, utilizamos la regresión logística dentro de scikit learn.\n\nfrom sklearn.linear_model import LogisticRegression\n\nEl uso del modelo es fácil. Como cualquier función, puedes pasar parámetros o no. El parámetro del solucionador es un optimizador, al igual que el solucionador en Excel. LBFGS es el valor predeterminado.\n\nclf_logistic = LogisticRegression(solver = \"lbfgs\")\n\nPara entrenar el modelo, llamamos al método de ajuste (fit). Dentro del método, debemos proporcionar al modelo columnas de entrenamiento (training_columns) y etiquetas de entrenamiento (training_labels). Usamos ravel de numpy para hacer que las etiquetas sean una matriz unidimensional en lugar de un marco de datos. En nuestros datos crediticios, las columnas de capacitación son todas las columnas excepto el estado del préstamo. El estado del préstamo contiene las etiquetas.\n\n\n2.1.5 Entrenamiento y prueba\nGeneralmente, en el Machine Learning, dividimos todo nuestro conjunto de datos en dos conjuntos de datos individuales. Son el conjunto de entrenamiento (train)y el conjunto de prueba (test).\n\n\n\n\n\n\n\n\nSubconjunto de datos\nUso\nPorción\n\n\n\n\nTrain\nAprenda de los datos para generar predicciones\n60%\n\n\nTest\npruebe el aprendizaje con nuevos datos.\n40%\n\n\n\nUsamos la mayoría de los datos para entrenar nuestros modelos, para que aprendan tanto como sea posible de los datos. Nuestro conjunto de pruebas se utiliza para ver cómo reacciona nuestro modelo a nuevos datos que no ha visto antes. Esto es como si los estudiantes aprendieran en la escuela. Aprenderán hechos de un tema y serán evaluados sobre diferentes hechos de ese mismo tema. De esta manera podemos evaluar su dominio del tema.\n\n\n2.1.6 Crear los conjuntos de entrenamiento y prueba\nLo primero que hacemos es separar nuestros datos en columnas y etiquetas de entrenamiento.\n\nimport pandas as pd\ncr_loan = pd.read_csv(\"cr_loan2.csv\")\nX = cr_loan.drop(\"loan_status\", axis = 1)\ny = cr_loan[[\"loan_status\"]]\n\nAquí, lo hemos asignado como X e \\(y\\). Una vez hecho esto, usamos la función train_test_split() den tren de prueba dentro del paquete scikit-learn. Echemos un vistazo al código.\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .4,random_state=123)\n\n¿Recuerda que dije que necesitamos columnas de entrenamiento y etiquetas para nuestro modelo? Lo necesitamos tanto para el conjunto de entrenamiento como para el conjunto de prueba, que se crean fácilmente con una línea de código. Dentro de esta función, establecemos el porcentaje de los datos que se utilizarán como conjunto de prueba (test_size)y un número utilizado como semilla aleatoria (random_state) para la reproductibilidad.\n\n\n2.1.7 Practica\nCreemos los conjuntos de datos \\(X\\) e \\(y\\)\n\ncr_loan_clean = pd.read_csv(\"cr_loan_w2.csv\")\nX = cr_loan_clean[[\"loan_int_rate\"]]\ny = cr_loan_clean[[\"loan_status\"]]\n\nAhora creamos y ajustamos un modelo de regresión logística a los datos de entrenamiento y llamemoslo clf_logistic_single.\n\nclf_logistic_single = LogisticRegression(solver ='lbfgs')\nclf_logistic_single.fit(X, np.ravel(y))\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\nImprimamos los parámetros del modelo\n\nprint(clf_logistic_single.get_params())\n\n{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n\nImprimimos la intersección del modelo\n\nprint(clf_logistic_single.intercept_)\n\n[-4.45785901]\n\n\n\n\n2.1.8 Regresión logística multivariada\nGeneralmente, no utilizará sólo loan_int_rate para predecir la probabilidad de incumplimiento. Querrás utilizar todos los datos que tienes para hacer predicciones.\nCon esto en mente, intentamos entrenar un nuevo modelo con diferentes columnas, llamadas características, a partir de los datos cr_loan_clean. ¿Se diferenciará este modelo del primero? Para ello, puede comprobar facilmente el .intercept_ de la regresión logística. Recuerde que esta es la intersección y de la función y las probabilidades logarítmicas generales de no incumplimiento.\nCreemos un nuevo conjunto de datos X con loan_int_rate y person_emp_length. Guárdelo como X_multi.\n\nX_multi = cr_loan_clean[[\"loan_int_rate\", \"person_emp_length\"]]\n\nCreemos un conjunto de datos y con solo loan_status.\n\ny = cr_loan_clean[[\"loan_status\"]]\n\nAhora, creemos y entrenemos un nuevo modelo de Regresión logística.\n\nclf_logistic_multi = LogisticRegression(solver='lbfgs').fit(X_multi, np.ravel(y))\n\nLuego, imprimamos la intersección del modelo\n\nprint(clf_logistic_multi.intercept_)\n\n[-4.21645549]\n\n\n\n2.1.8.1 Creación de conjuntos de entrenamiento y prueba\nComenzamos creando el conjunto de datos X utilizando la tasa de interés, la duración de empleo y los ingresos. Cree el conjunto y utilizando el estado de préstamo.\n\nX = cr_loan_clean[['loan_int_rate','person_emp_length','person_income']]\ny = cr_loan_clean[['loan_status']]\n\nUsemos test_train_split para crear el conjunto de entrenamiento y prueba.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n\nLuego creamos y adaptamos el modelo de regresión logística.\n\nclf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n\nPor último, imprimimos los coeficientes del modelo\n\nprint(clf_logistic.coef_)\n\n[[ 1.28517496e-09 -2.27622202e-09 -2.17211991e-05]]"
  },
  {
    "objectID": "summary.html#predecir-la-probabilidad-de-incumplimiento",
    "href": "summary.html#predecir-la-probabilidad-de-incumplimiento",
    "title": "2  Regresión logistica para incumplimiento",
    "section": "2.2 Predecir la probabilidad de incumplimiento",
    "text": "2.2 Predecir la probabilidad de incumplimiento\nHasta ahora, hemos entrenado una regresión logística con nuestros datos crediticios y hemos analizado algunos atributos del modelo. Ahora, analicemos la estructura del modelo y cómo crear predicciones.\n\n2.2.1 Coeficientes de regresión logística\nEn el ejercicio anterior, vimos los siguientes interceptos y coeficientes para nuestro modelo. Estos coeficientes, determinan la importancia de cada columna. Estos valores son parte de la fórmula de regresión logística que calcula la probabilidad de incumplimiento que vemos aquí.\n\\[\nP(loan_status = 1) = \\frac{1}{1 + e^{-(-4.22 + (1.29e^{-09}*int\\_rate) + (-2.28e^{-09}*Emp\\_Length) + (-2.17e^{-05}*Income))}}\n\\]\nCada coeficiente se multiplica por los valores de la columna y luego se suma junto con la intersección. Luego, solamente se realiza la sustitución en el modelo. El resultado será la probabilidad de incumplimiento.\n\n\n2.2.2 Interpretación de coeficientes\nConsideremos la duración de empleo (emp_length) como ejemplo. Suponga que:\n\nIntercepto = \\(-1.02\\)\ncoeficiente para employment_length = \\(-0.056\\)\n\nLo que este coeficiente nos dice son las probabilidades logarítmicas de no incumplimiento. Esto significa que por cada año de aumento en la duración del empleo, la persona tiene menos probabilidad de incumplimiento por un factor del coeficiente.\nDigamos que tenemos 3 valores para la duración del empleo y queremos saber cómo afecta nuestra probabilidad de incumplimiento al observar los coeficientes.\n\n\n\nIntercept\nperson_emp_length\nvalor*coef\nprobability of default\n\n\n\n\n-1.02\n10\n(10*-0.06)\n0.17\n\n\n-1.02\n11\n(11*-0.06)\n0.16\n\n\n-1.02\n12\n(12*-0.06)\n0.15\n\n\n\nLo que vemos aquí es que cuanto mayor es la duración del empleo de una persona, es menos probable que incumpla.\n\n\n2.2.3 Usar columnas no numéricas\nYa que estamos hablando de números, vale la pena mencionar que hasta ahora solo hemos usado columnas numéricas para entrenar modelos. Nuestros datos tamboién contienen columnas no numéricas, como la intención de préstamo, que utiliza palabras para describir cómo la persona planea usar el dinero que le prestamos.\n\ncr_loan[\"loan_intent\"]\n\n0               PERSONAL\n1              EDUCATION\n2                MEDICAL\n3                MEDICAL\n4                MEDICAL\n              ...       \n32576           PERSONAL\n32577           PERSONAL\n32578    HOMEIMPROVEMENT\n32579           PERSONAL\n32580            MEDICAL\nName: loan_intent, Length: 32581, dtype: object\n\n\nEn Python, a diferencia de R, los modelos de aprendizaje automático no saben cómo usar estos valores no numéricos. Por lo tanto, tenemos que realizar una operación llamada codificación one-hot antes de poder usarlos.\n\n\n2.2.4 Codificación one-hot\nLa codificación one-hot suena complicada, pero es realmente simple. La idea principal es representar una cadena con un valor numérico. Así es como funciona. Pensemos en la columna de intención de préstamo donde cada préstamo tiene su propio valor de intención como una cadena.\n\nEsta muestra tiene eduación, medicina y riesgo.\nCon la codificación one-hot, obtenemos un nuevo conjunto de columnas donde cada valor de la intención de préstamo ahora es su propia columna.\n\nNote que cada nueva columna se crea separando los préstamos con cada valor de intención y haciendo que el valor de la nueva columna sea 0 o 1. Por ejemplo, si la intención del préstamo era eduación, ahora se representa con un 1 en la columna de educación, aahora se representa con un 1 en la columna de eduación de intención del préstamo. De esta manera, hay un valor candente.\n\n\n2.2.5 Función Get dummies\nPara codificar nuestras columnas de cadena, usamos la función get_dummies() que pertenece a pandas. Primero, separamos las columnas numéricas y no numéricas de los datos en dos conjuntos.\n\n# separamos las columnas numéricas\ncred_num = cr_loan.select_dtypes(exclude = [\"object\"])\ncred_num.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\n\n\n0\n22\n59000\n123.0\n35000\n16.02\n1\n0.59\n3\n\n\n1\n21\n9600\n5.0\n1000\n11.14\n0\n0.10\n2\n\n\n2\n25\n9600\n1.0\n5500\n12.87\n1\n0.57\n3\n\n\n3\n23\n65500\n4.0\n35000\n15.23\n1\n0.53\n2\n\n\n4\n24\n54400\n8.0\n35000\n14.27\n1\n0.55\n4\n\n\n\n\n\n\n\n\n# Separamos las columnas no numéricas\ncred_cat = cr_loan.select_dtypes(include = [\"object\"])\ncred_cat.head()\n\n\n\n\n\n\n\n\nperson_home_ownership\nloan_intent\nloan_grade\ncb_person_default_on_file\n\n\n\n\n0\nRENT\nPERSONAL\nD\nY\n\n\n1\nOWN\nEDUCATION\nB\nN\n\n\n2\nMORTGAGE\nMEDICAL\nC\nN\n\n\n3\nRENT\nMEDICAL\nC\nN\n\n\n4\nRENT\nMEDICAL\nC\nY\n\n\n\n\n\n\n\nLuego usamos la función get_dummies() para codificar solo las columnas no numéricas.\n\n# One-hot a columnas no numéricas\ncred_cat_onehot = pd.get_dummies(cred_cat)\ncred_cat_onehot.head()\n\n\n\n\n\n\n\n\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\nperson_home_ownership_RENT\nloan_intent_DEBTCONSOLIDATION\nloan_intent_EDUCATION\nloan_intent_HOMEIMPROVEMENT\nloan_intent_MEDICAL\nloan_intent_PERSONAL\nloan_intent_VENTURE\nloan_grade_A\nloan_grade_B\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n\n\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n\n\n2\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\n\nUnimos los dos conjuntos y el resultado es un conjunto de datos completo que esta listo para aplicarle el Machine Learning.\n\ncr_loan_prep = pd.concat([cred_num, cred_cat_onehot], axis = 1)\ncr_loan_prep.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\n...\nloan_intent_VENTURE\nloan_grade_A\nloan_grade_B\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n0\n22\n59000\n123.0\n35000\n16.02\n1\n0.59\n3\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n\n\n1\n21\n9600\n5.0\n1000\n11.14\n0\n0.10\n2\n0\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n\n\n2\n25\n9600\n1.0\n5500\n12.87\n1\n0.57\n3\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n3\n23\n65500\n4.0\n35000\n15.23\n1\n0.53\n2\n0\n0\n...\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n4\n24\n54400\n8.0\n35000\n14.27\n1\n0.55\n4\n0\n0\n...\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n\n\n\n\n5 rows × 27 columns\n\n\n\n\n\n2.2.6 Prediciendo el futuro\nUna vez nuestro modelo está entrenado, utilizamos el método predict_proba() en datos de prueba para hacer predicciones. Esto crea un conjunto de probabilidades de no incumplimiento e incumplimiento. Claramente el resultado será una serie de números entre 0 y 1.\n\n\n2.2.7 Práctica\nImprimamos las nuevas columnas del conjunto de datos cr_loan_prep\n\nprint(cr_loan_prep.columns)\n\nIndex(['person_age', 'person_income', 'person_emp_length', 'loan_amnt',\n       'loan_int_rate', 'loan_status', 'loan_percent_income',\n       'cb_person_cred_hist_length', 'person_home_ownership_MORTGAGE',\n       'person_home_ownership_OTHER', 'person_home_ownership_OWN',\n       'person_home_ownership_RENT', 'loan_intent_DEBTCONSOLIDATION',\n       'loan_intent_EDUCATION', 'loan_intent_HOMEIMPROVEMENT',\n       'loan_intent_MEDICAL', 'loan_intent_PERSONAL', 'loan_intent_VENTURE',\n       'loan_grade_A', 'loan_grade_B', 'loan_grade_C', 'loan_grade_D',\n       'loan_grade_E', 'loan_grade_F', 'loan_grade_G',\n       'cb_person_default_on_file_N', 'cb_person_default_on_file_Y'],\n      dtype='object')\n\n\n\n\n2.2.8 Recordemos como predecir la probabilidad de incumplimiento\n\ncr_loan_clean = pd.read_csv(\"cr_loan_w2.csv\")\nX = cr_loan_clean[[\"loan_intent_DEBTCONSOLIDATION\", \"loan_intent_EDUCATION\", \"loan_intent_HOMEIMPROVEMENT\", \"loan_intent_MEDICAL\", \"loan_intent_PERSONAL\",\"loan_intent_VENTURE\",\"person_home_ownership_MORTGAGE\",\"person_home_ownership_OTHER\",\"person_home_ownership_OWN\", \"person_home_ownership_RENT\"]]\ny = cr_loan_clean[[\"loan_status\"]]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .4,random_state=123)\n\nEntrenemos el modelo de regresión logistica con los datos de entrenamiento.\n\nclf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n\nAhora creamos predicciones de probabilidad para el estado del prestamó utilizando datos de prueba.\n\npreds = clf_logistic.predict_proba(X_test)\n\nLuego, creemos un marco de datos de las predicciones y valores reales\n\npreds_df = pd.DataFrame(preds[:,1][0:1000], columns = ['prob_default'])\ntrue_df = y_test.head(n=1000)\n\nPor último, concatenamos e imprimimos los marcos de datos para comparación.\n\nprint(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))\n\n     loan_status  prob_default\n0              1      0.401990\n1              1      0.401990\n2              0      0.224612\n3              0      0.224612\n4              1      0.255862\n..           ...           ...\n995            1      0.224612\n996            0      0.166742\n997            0      0.255862\n998            0      0.224612\n999            0      0.116630\n\n[1000 rows x 2 columns]"
  },
  {
    "objectID": "summary.html#desempeño-del-modelo-de-crédito",
    "href": "summary.html#desempeño-del-modelo-de-crédito",
    "title": "2  Regresión logistica para incumplimiento",
    "section": "2.3 Desempeño del modelo de crédito",
    "text": "2.3 Desempeño del modelo de crédito\nYa vimos predicciones de probabilidad de incumplimiento frenta a valores reales del estado del préstamo, pero ¿cómo analizamos el desempeño de nuestro modelo?\n\n2.3.1 Puntuación de la presición (accurary) del modelo\nLa forma más sencilla de analizar el rendimiento es con el accuracy. La precisión es el número de predicciones correctas dividido por el número total de predicciones.\n\\[\naccuracy = \\frac{\\mbox{número total de predicciones correctas}}{\\mbox{total de predicciones}}\n\\]\nUna forma de comprobar esto es utilizar el método de scikit-learn en la regresión logística.\n\nclf_logistic.score(X_test, y_test)\n\n0.7805498981670062\n\n\nEsto se utiliza en el modelo entrenado y devuelve la precisión promedio del conjunto de prueba. El uso del método de puntuación mostrará esta precisión como porcentaje. En este ejemplo, nos dice que el 78.1% de los préstamos se predijeron correctamente.\n\n\n2.3.2 Gráficos de curvas ROC\nLos gráficos ROC son una excelente manera de visualizar el rendimienrto de nuestro modelo. Trazan la tasa sde verdaderos positivos, el porcentaje de impagos pronósgticados correctamente, frente a la tasa de falson positivos, el porcentaje de impagos predichos incorrectamente.\nUsando la función roc_curve de scikit.learrn, creamos dos valores y los umbrales todos a la vez. A partir de ahí utilizamos un gráfico de lineas normal para ver los resultados. La línea azul punteada representa una predicción aleatoria y la línea naranja representa las predicciones de nuestro modelo.\n\nfrom sklearn.metrics import roc_curve\nresultados = pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1)\nprob_default = resultados[\"prob_default\"]\n\nfallout, sensitivity, thresholds = roc_curve(y_test.head(n=1000),prob_default)\n\nimport matplotlib.pyplot as plt\nplt.plot(fallout, sensitivity, color = \"darkorange\")\n\n\n\n\nLos gráficos ROC se interpretan obsevando qué tan lejos está la curva del modelo de la linea azul punteada que se muestra aquí, que representa la predicción aleatoria. Este movimiento de alejamiento de la línea se llama elevación. Cuanto más elevación tengamos, mayor será el área bajo la curva. El AUC es el aréa calculada entre la curva y las predicción aleatoria. Este es un indicador directo de qué tan bien nuestro modelo hace predicciones.\n\n\n2.3.3 Umbrales Predeterminados\nPara analizar más a fondo el rendimiento, debemos decidir qué rango de probabilidad es un incumplimiento y cuál no es un incumplimiento. Digamos que decidimos que cualquier probabilidad superior a 0.5 es un valor predeterminado, y cualquier probabilidad inferior a eso no es un valor predeterminado.\n\n\n\n2.3.4 Establecer un umbral\nUna vez definido el umbral, debemos volver a etiquetar nuestros préstamos en función de ese umbral. Para eso, primero necesitaremos crear una variable para almacenar las probabilidades predichas.\n\npreds = clf_logistic.predict_proba(X_test)\npreds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\npreds_df[\"loan_status\"] = preds_df[\"prob_default\"].apply(lambda x:1 if x &gt; 0.5 else 0)\n\nLuego podemos crear un marco de datos a partir de la segunda columna que contiene las probabilidades de incumplimiento. Luego aplicamos una función rápida para asignar un valor de 1 si la probabilidad de incumplimiento está por encima de nuestro umbral de 0.5. La lambda está ahí solo para decirle a Python que queremos usar una función única sin definirla. El resultado de esto es un marco de datos con nuevos valores para el estado del préstamo según nuestro umbral.\n\npreds_df.head()\n\n\n\n\n\n\n\n\nprob_default\nloan_status\n\n\n\n\n0\n0.401990\n0\n\n\n1\n0.401990\n0\n\n\n2\n0.224612\n0\n\n\n3\n0.224612\n0\n\n\n4\n0.255862\n0\n\n\n\n\n\n\n\n\n\n2.3.5 Informes de clasificación crediticia\nOtra función realmente útil para evaluar nuestros modelos es la función informes de clasificación classification_report() de scikit.learn. Esto nos mostrará varias métricas de evaluación diferentes a la vez. Usamos esta función para evaluar nuestro modelo usando nuestros valores verdaderos para el estado del préstamo almacenado en el conjunto y_test, y nuestros valores de estado del préstamo previstos a partir de nuestra regresión logística y el umbral que establecimos.\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import classification_report\ntarget_names = ['Non-Default', 'Default']\nclassification_report(y_test, preds_df['loan_status'], target_names=target_names)\n\n'              precision    recall  f1-score   support\\n\\n Non-Default       0.78      1.00      0.88      9198\\n     Default       0.00      0.00      0.00      2586\\n\\n    accuracy                           0.78     11784\\n   macro avg       0.39      0.50      0.44     11784\\nweighted avg       0.61      0.78      0.68     11784\\n'\n\n\nHay dos métricas realmente útiles en esta tabla, y son la precisión y la recuperación.\n\n\n2.3.6 Seleccionar métricas de clasificación\nA veces, después de generar el informe, desea seleccionar o almacenar valores específicos dentro del informe. Para hacer esto, puede utilizar la función precision_recall_fscore_support(). Con esta función, podemos recuperar valores predeterminados subconjuntos del informe como lo haríamos con cualquier matriz.\n\nfrom sklearn.metrics import precision_recall_fscore_support\nprecision_recall_fscore_support(y_test, preds_df[\"loan_status\"])[1][1]\n\n0.0\n\n\nAquí seleccionamos el segundo valor del segundo conjunto.\n\n\n2.3.7 Práctica\n\n2.3.7.1 Informes de clasificación\n\nComencemos creando un marco de datos para las probabilidades de incumplimiento de preds y llamelo preds_df\nReasigne el estado del préstamo al umbral\nImprima el recuento de filas para el estado del préstamo\nPor último, imprima el informe de metricas.\n\n\n# Marco de probabilidades preds_df\npreds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\n\n# umbral del estado del préstamo\npreds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x &gt; 0.50 else 0)\n\n#recuento de filas\nprint(preds_df['loan_status'].value_counts())\n\n# Reporte de metricas \ntarget_names = ['Non-Default', 'Default']\n\n0    11784\nName: loan_status, dtype: int64\n\n\n\nprint(classification_report(y_test, preds_df['loan_status'], target_names=target_names))\n\n              precision    recall  f1-score   support\n\n Non-Default       0.78      1.00      0.88      9198\n     Default       0.00      0.00      0.00      2586\n\n    accuracy                           0.78     11784\n   macro avg       0.39      0.50      0.44     11784\nweighted avg       0.61      0.78      0.68     11784\n\n\n\n\n\n2.3.7.2 Seleccionar métricas del reporte\nImprimimos los dos primeros valores del informe\n\nprint(precision_recall_fscore_support(y_test,preds_df['loan_status'])[0])\n\n[0.7805499 0.       ]\n\n\n\n\n2.3.7.3 Puntuación visual\nCreé predicciones y almacenarlos en una variable preds\n\npreds = clf_logistic.predict_proba(X_test)\n\nImprima la puntuación (accuracy) del modelo\n\nprint(clf_logistic.score(X_test, y_test))\n\n0.7805498981670062\n\n\nTrazemos la curva ROC de las probabilidades de default\n\nprob_default = preds[:, 1]\nfallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\nplt.plot(fallout, sensitivity, color = 'darkorange')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.show()\n\n\n\n\nCalcular el AUC del modelo utilizando datos de prueba y probabilidades de incumplimiento y guárdelos en auc\n\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, prob_default)\nauc\n\n0.6862234627824368"
  },
  {
    "objectID": "summary.html#modelo-de-discriminación-e-impacto",
    "href": "summary.html#modelo-de-discriminación-e-impacto",
    "title": "2  Regresión logistica para incumplimiento",
    "section": "2.4 Modelo de discriminación e impacto",
    "text": "2.4 Modelo de discriminación e impacto\nHemos analizado algunas formas de evaluar nuestra regresión logística. Hablamos más sobre los umbrales y su impacto en el rendimiento de la cartera.\n\n2.4.1 Matrices de confusión\nOtra forma de analizar el desempeño de nuestro modelo es con la matriz de confusión. Estos nos mostrará todas nuestras predicciones correctas e incorrectas sobre el estado del préstamo. La matriz de confusión tiene cuatro secciones:\n\nverdaderos positivos,\nfalsos positivos,\nfalsos negativos,\nverdaderos negativos\n\nHemos analizado la recuperación de valores predeterminados dentro de los informes de clasificación. Aquí se muestra esa fórmula y dónde reside en la matriz de confusión.\n\n\n\n\n\n\n\nVerdaderos positivodos (predicted = 0, Actual = 0)\nFalsos positivos (predicted = 1, actual = 0)\n\n\nFalsos Negativos (predicted = 0, Actual = 1)\nVerdaderos positivos (predicted = 1, actual = 1)\n\n\n\n\\[\n\\begin{eqnarray*}\nPrecision(0) &=& \\frac{TN}{TN + FN}\\\\[0.2cm]\nPrecision(1) &=& \\frac{TP}{TP + FP}\\\\[0.2cm]\nsensibilidad(0) &=& \\frac{TN}{TN + FP}\\\\[0.2cm]\nsensibilidad(1) &=& \\frac{TP}{TP + FN}\n\\end{eqnarray*}\n\\]\n\n\n2.4.2 Retiro predeterminado para el estado del préstamo\nLa definición de recuperación predeterminada, tambien llamada sensibilidad, es la proporción de positivos reales predichos correctamente. Antes, recuperábamos este valor del informe de clasificación sin entender cómo se cálcula.\n\nLa sensibilidad se obtiene tomando el número de valores predeterminados verdaderos y dividiéndolo por la suma de los valores predeterminados verdaderos y los valores predeterminados previstos como no predeterminados.\n\n\n2.4.3 Recordar el impacto de la cartera\nVeamos el retiro de valores predeterminados resaltados en rojo en un informe de clasificación.\n\nEste es un ejemplo de un informe de un modelo de regresión logística de bajo rendimiento. En este caso, la proporción de incumplimientos reales predichos por nuestro modelo fue sólo de 4%.\nImaginemos que tenemos 50,000 préstamos en nuestra cartera y cada unno de ellos tiene un monto total de préstamo de 50 dólares. Como se ve en el informe de clasificación, este modelo tiene un retiro por defecto del 4%.\n\n\n\n\n\n\n\n\nMonto Préstamo\nDefault Predicted/Not Predicted\nPerdida estimada, por incumplimiento\n\n\n\n\n50\n0.04/0.96\n(50000x0.96)x50 = $2,400,000\n\n\n\nEntonces, eso significa que predijimos correctamente el 4% de los incumplimientos y predijimos incorrectamente el 96% de los incumplimientos. Si todos nuestros préstamos en default verdadero incumplieran ahora mismo, nuestra pérdida de la cartera sería de 2.4 millones de dólares. Esta pérdida sería algo que no planeamos y sería inesperada.\n\n\n2.4.4 Recuperación, precisión y exactitud (accuracy)\nCuando se trata de métricas como recuperación, precisión y exactitud, puede resultar complicado encontrar un número óptimo para las tres como objetivo. Eche un vistazo a este gráfico de ejemplo de un modelo de regresión logística sobre los datos crediticios.\n\nLa línea azul, que es la recuperación predeterminada, comienza muy alta. Esto se debe a que si predecimos que todos los préstamos serán predeterminados, definitivamente predecimos todos nuestros incumplimientos correctamente. También puede ver que cuando la recuperación predeterminada es alta, la mayoría de las veces la recuperación no predeterminada es baja. Inicialmente, tenemos que determinar qué puntajes de cada uno son lo suficientemente buenos para establecer una línea de base para es desempeño.\n\n\n2.4.5 Práctica\nReasignemos valores loan_status utilizando un umbral de 0.5 probabilidad de incumplimiento dentro de preds_df.\n\npreds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x &gt; 0.5 else 0)\n\nImprimamos la matriz de confusión de los datos y_test y los nuevos valores del estado del préstamo.\n\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,preds_df['loan_status']))\n\n[[9198    0]\n [2586    0]]\n\n\nAhora, hagamos lo mismo, pero reasignando valores loan_status utilizando un umbral de 0.4\n\npreds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x &gt; 0.4 else 0)\n\n\nprint(confusion_matrix(y_test,preds_df['loan_status']))\n\n[[8546  652]\n [2238  348]]\n\n\n\n2.4.5.1 Veamos como afectan los umbrales al rendimiento\nReasignemos los valores loan_status utilizando el umbral 0.4.\n\npreds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x &gt; 0.4 else 0)\n\nAhora almacenamos el número de valores predeterminados preds_df seleccionando el segundo valor del recuento de valorrs y guárdamos como num_default\n\nnum_defaults = preds_df['loan_status'].value_counts()[1]\n\nObtenga la tasa de recuperación predeterminada de la matriz de clasificación y guárdela como default_recall\n\ndefault_recall = precision_recall_fscore_support(y_test,preds_df['loan_status'])[1][1]"
  }
]